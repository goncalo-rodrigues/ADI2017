{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Learning and Decision Making"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Laboratory 4: Partially observable Markov decision problems\n",
    "\n",
    "In the end of the lab, you should submit all code/answers written in the tasks marked as \"Activity n. XXX\", together with the corresponding outputs and any replies to specific questions posed to the e-mail <adi.tecnico@gmail.com>. Make sure that the subject is of the form [&lt;group n.&gt;] LAB &lt;lab n.&gt;."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 1. Modeling\n",
    "\n",
    "Consider once again the guessing game domain described in the Homework and which you described as a POMDP.\n",
    "\n",
    "Recall that:\n",
    "\n",
    "* The opponent can hold one of two cards in hand: an Ace of Clubs (A&clubs;) and an Ace of Diamonds (A&diams;). The agent must guess which card the opponent is holding. \n",
    "\n",
    "* For every right answer, the agent wins 1EUR, and every wrong answer costs the agent 1EUR. \n",
    "\n",
    "* The agent can also try to _peek_. \n",
    "\n",
    "* When the agent peeks, it sees the right card with a probability of 0.9 and the wrong card with probability 0.1.\n",
    "\n",
    "* The game restarts whenever the agent makes a guess.\n",
    "\n",
    "Consider throughout that $\\gamma=0.9$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "---\n",
    "\n",
    "#### Activity 1.        \n",
    "\n",
    "Implement your POMDP in Python. In particular,\n",
    "\n",
    "* Create a list with all the states;\n",
    "* Create a list with all the actions;\n",
    "* Create a list with all the observations\n",
    "* For each action, define a `numpy` array with the corresponding transition probabilities;\n",
    "* For each action, define a `numpy` array with the corresponding observation probabilities;\n",
    "* Define a `numpy`array with the cost that you defined in your homework.\n",
    "\n",
    "The order for the states and actions used in the transition probability and cost matrices should match that in the lists of states and actions. \n",
    "\n",
    "**Note**: Don't forget to import `numpy`.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ppeek\n",
      " [[ 1.  0.]\n",
      " [ 0.  1.]]\n",
      "PAc\n",
      " [[ 0.5  0.5]\n",
      " [ 0.5  0.5]]\n",
      "PAd\n",
      " [[ 0.5  0.5]\n",
      " [ 0.5  0.5]]\n",
      "OPeek\n",
      " [[ 0.9  0.1  0. ]\n",
      " [ 0.1  0.9  0. ]]\n",
      "OAc\n",
      " [[ 0.  0.  1.]\n",
      " [ 0.  0.  1.]]\n",
      "OAd\n",
      " [[ 0.  0.  1.]\n",
      " [ 0.  0.  1.]]\n",
      "c\n",
      " [[ 0.5  0.   1. ]\n",
      " [ 0.5  1.   0. ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "states = ['Ac', 'Ad']\n",
    "actions = ['peek', 'guessAc', 'guessAd']\n",
    "observations = ['seeAc', 'seeAd', 'seeNothing']\n",
    "\n",
    "Ppeek = np.identity(2)\n",
    "PAc = np.ones((2,2)) * 0.5\n",
    "PAd = PAc\n",
    "\n",
    "P = np.zeros((3,2,2))\n",
    "P[0] = Ppeek\n",
    "P[1] = PAc\n",
    "P[2] = PAd\n",
    "\n",
    "Opeek = np.zeros((2,3))\n",
    "Opeek[:, 0] = [0.9, 0.1]\n",
    "Opeek[:, 1] = [0.1, 0.9]\n",
    "OAc = np.zeros((2,3))\n",
    "OAc[:, 2] = 1\n",
    "OAd = OAc\n",
    "\n",
    "O = np.zeros((3,2,3))\n",
    "O[0] = Opeek\n",
    "O[1] = OAc\n",
    "O[2] = OAd\n",
    "\n",
    "c = np.ones((2,3))\n",
    "c[:,0] = [0.5, 0.5]\n",
    "c[:,1] = [0, 1]\n",
    "c[:,2] = [1, 0]\n",
    "\n",
    "print('Ppeek\\n', Ppeek)\n",
    "print('PAc\\n', PAc)\n",
    "print('PAd\\n', PAd)\n",
    "print('OPeek\\n', Opeek)\n",
    "print('OAc\\n', OAc)\n",
    "print('OAd\\n', OAd)\n",
    "print('c\\n', c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2. Sampling\n",
    "\n",
    "You are now going to sample random trajectories of your POMDP and observe the impact it has on the corresponding belief."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "raw_mimetype": "text/latex"
   },
   "source": [
    "---\n",
    "\n",
    "#### Activity 2.\n",
    "\n",
    "Generate a random POMDP trajectory using a uniformly random policy. In particular, from a random initial state $x_0$ generate:\n",
    "\n",
    "1. A sequence of 10,000 states by selecting the actions uniformly at random;\n",
    "2. The corresponding sequence of 10,000 actions;\n",
    "3. The corresponding sequence of 10,000 observations.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_random_trajectory(x0, n=10000):\n",
    "    indexx = states.index(x0)\n",
    "    x = np.zeros(2)\n",
    "    x[indexx] = 1\n",
    "    trajectory_states = []\n",
    "    trajectory_actions = []\n",
    "    trajectory_observations = []\n",
    "    current_state = x\n",
    "    for i in range(n):\n",
    "        action = np.random.choice(len(actions))\n",
    "        Paction = P[action]\n",
    "        Oaction = O[action]\n",
    "        index_state = np.random.choice(len(states), p = current_state.dot(Paction))\n",
    "        current_state = np.zeros(2)\n",
    "        current_state[index_state] = 1\n",
    "        obs = np.random.choice(len(observations), p = current_state.dot(Oaction))\n",
    "        \n",
    "        trajectory_states.append(states[current_state.argmax()])\n",
    "        trajectory_actions.append(actions[action])\n",
    "        trajectory_observations.append(observations[obs])\n",
    "    return trajectory_states, trajectory_actions, trajectory_observations\n",
    "        \n",
    "rnd_s, rnd_a, rnd_o = get_random_trajectory(states[np.random.choice(len(states))])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "---\n",
    "\n",
    "#### Activity 3.\n",
    "\n",
    "For the POMDP trajectory generated in Activity 2, compute the corresponding sequence of beliefs, assuming that the initial belief is $\\mathbf{b}_0=[0.5, 0.5]$. Report the resulting beliefs, ignoring duplicate beliefs or beliefs whose distance is smaller than $10^{-4}$.\n",
    "\n",
    "**Note 1:** You may want to define a function `belief_update` that receives a belief, an action and an observation and returns the updated belief.\n",
    "\n",
    "**Note 2:** To compute the distance between vectors, you may find useful `numpy`'s function `linalg.norm`.\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 0.5,  0.5]), array([ 0.1,  0.9]), array([ 0.9,  0.1]), array([ 0.98780488,  0.01219512]), array([ 0.01219512,  0.98780488]), array([ 0.00136986,  0.99863014]), array([  1.52392563e-04,   9.99847607e-01]), array([ 0.99863014,  0.00136986]), array([  9.99847607e-01,   1.52392563e-04])]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# b is the belief\n",
    "# a is the index of the action\n",
    "# z is the index of the observation\n",
    "def belief_update(b, a, z):\n",
    "    res = b.dot(P[a]).dot(np.diag(O[a][:, z]))\n",
    "    return res/np.sum(res)\n",
    "\n",
    "current_belief = np.ones(2) * 0.5\n",
    "beliefs = []\n",
    "beliefs.append(current_belief)\n",
    "for i in range(len(rnd_s)):\n",
    "    current_belief = belief_update(current_belief, actions.index(rnd_a[i]), observations.index(rnd_o[i]))\n",
    "    is_dup = False\n",
    "    for k in beliefs:\n",
    "        if (np.linalg.norm(current_belief - k) < 10e-4):\n",
    "            is_dup = True\n",
    "            break\n",
    "    if (not is_dup):\n",
    "        beliefs.append(current_belief)\n",
    "    \n",
    "print(beliefs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 3. Solution methods\n",
    "\n",
    "In this section you are going to compare different non-exact solution methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "---\n",
    "\n",
    "#### Activity 4\n",
    "\n",
    "Compute the solution for the underlying MDP and report the corresponding optimal policy and optimal cost-to-go. \n",
    "\n",
    "** Note:** You may reuse code from previous labs.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(probs, policy, costs, gama = 0.99):\n",
    "    # computes transition probabilities for a given policy \n",
    "    Ppolicy = np.einsum('nrm,rn->rm', probs, policy)\n",
    "    # computes cost for a given policy\n",
    "    Cpolicy = np.sum(costs * policy, axis=1).reshape(-1, 1)\n",
    "   \n",
    "    I = np.identity((len(states)))\n",
    "    # computes discounted cost-to-go \n",
    "    return np.dot(np.dot(I, np.linalg.inv(I - gama*Ppolicy)), Cpolicy), Ppolicy, Cpolicy\n",
    "\n",
    "# computes C + gama * PJ for every action. returns an array of J's for every action\n",
    "def calculateQ(j, c, gama):\n",
    "    result = np.zeros(shape=(len(states), len(actions)))\n",
    "    for i in range(len(actions)):\n",
    "        result[:, i] = (c[:, i].reshape(-1, 1) + gama * P[i].dot(j)).reshape(-1)\n",
    "    return result\n",
    "\n",
    "\n",
    "def policy_iteration(gama, P, c):\n",
    "    exit = False\n",
    "    iterations = 0\n",
    "    policy = np.ones(shape = (len(states), len(actions))) / len(actions)\n",
    "    while not exit:\n",
    "        # evaluates policy\n",
    "        ev, _, _ = evaluate(P, policy, c)\n",
    "        # computes Q function\n",
    "        Q = calculateQ(ev, c, gama)\n",
    "        a = np.isclose(Q, Q.min(axis=1).reshape(-1, 1), atol=1e-10, rtol=1e-10)\n",
    "        # improves policy\n",
    "        newpolicy = np.divide(a,np.sum(a, axis=1).reshape(-1, 1))\n",
    "        exit = (policy == newpolicy).all()\n",
    "        policy = newpolicy \n",
    "        iterations += 1\n",
    "    return newpolicy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  1.  0.]\n",
      " [ 0.  0.  1.]]\n",
      "[[ 0.]\n",
      " [ 0.]]\n"
     ]
    }
   ],
   "source": [
    "gama = 0.99\n",
    "optimal_policy_mdp = policy_iteration(gama, P, c)\n",
    "optimal_cost_mdp, _, _ = evaluate(P, optimal_policy_mdp, c, gama)\n",
    "print(optimal_policy_mdp)\n",
    "print(optimal_cost_mdp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "---\n",
    "\n",
    "#### Activity 5\n",
    "\n",
    "For each of the beliefs computed in Activity 3, compute the action prescribed by:\n",
    "\n",
    "* The MLS heuristic;\n",
    "* The AV heuristic;\n",
    "* The Q-MDP heuristic.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             [ 0.5  0.5]\t mls: guessAc\t avs: guessAc\t qmdp: peek\n",
      "                             [ 0.1  0.9]\t mls: guessAd\t avs: guessAd\t qmdp: guessAd\n",
      "                             [ 0.9  0.1]\t mls: guessAc\t avs: guessAc\t qmdp: guessAc\n",
      "               [ 0.98780488  0.01219512]\t mls: guessAc\t avs: guessAc\t qmdp: guessAc\n",
      "               [ 0.01219512  0.98780488]\t mls: guessAd\t avs: guessAd\t qmdp: guessAd\n",
      "               [ 0.00136986  0.99863014]\t mls: guessAd\t avs: guessAd\t qmdp: guessAd\n",
      "     [  1.52392563e-04   9.99847607e-01]\t mls: guessAd\t avs: guessAd\t qmdp: guessAd\n",
      "               [ 0.99863014  0.00136986]\t mls: guessAc\t avs: guessAc\t qmdp: guessAc\n",
      "     [  9.99847607e-01   1.52392563e-04]\t mls: guessAc\t avs: guessAc\t qmdp: guessAc\n"
     ]
    }
   ],
   "source": [
    "def mls_heuristic(b):\n",
    "    return optimal_policy_mdp[b.argmax()].argmax()\n",
    "    \n",
    "def avs_heuristic(b):\n",
    "    return b.dot(optimal_policy_mdp).argmax()\n",
    "\n",
    "def qmdp_heuristic(b):\n",
    "    return b.dot(calculateQ(optimal_cost_mdp, c, gama)).argmin()\n",
    "\n",
    "for belief in beliefs:\n",
    "    print('%40s\\t mls: %s\\t avs: %s\\t qmdp: %s' % (belief, actions[mls_heuristic(belief)], actions[avs_heuristic(belief)], actions[qmdp_heuristic(belief)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "---\n",
    "\n",
    "#### Activity 6\n",
    "\n",
    "Suppose that the optimal cost-to-go function for the POMDP can be represented using the $\\alpha$-vectors\n",
    "\n",
    "$$\n",
    "\\left\\{\n",
    "\\begin{bmatrix}\n",
    "2.795\\\\\n",
    "3.795\n",
    "\\end{bmatrix},\n",
    "\\begin{bmatrix}\n",
    "3.795\\\\\n",
    "2.795\n",
    "\\end{bmatrix},\n",
    "\\begin{bmatrix}\n",
    "3.105\\\\\n",
    "3.105\n",
    "\\end{bmatrix}\\right\\}$$\n",
    "\n",
    "corresponding to the actions 'Guess clubs', 'Guess diamonds' and 'Peek', respectively. Represent the optimal cost-to-go function and compare the optimal policy with the MDP heuristics from Activity 5 in the beliefs computed in Activity 3.\n",
    "\n",
    "** Note: ** Don't forget to import `matplotlib`, and use the magic `%matplotlib notebook`.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nW0gAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x223af2e7e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "a_clubs = np.array([2.795, 3.795])\n",
    "a_diamonds = np.array([3.795, 2.795])\n",
    "a_peek = np.array([3.105, 3.105])\n",
    "a = np.zeros((3,1,2))\n",
    "a[0]=a_peek\n",
    "a[1]=a_clubs\n",
    "a[2]=a_diamonds\n",
    "plt.axis([0, 1, 2.5, 3.9])\n",
    "plt.plot(a_clubs)\n",
    "plt.plot(a_diamonds)\n",
    "plt.plot(a_peek)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.105]\n",
      " [ 3.295]\n",
      " [ 3.295]]\n",
      "                             [ 0.5  0.5]\t mls: guessAc\t avs: guessAc\t qmdp: peek \t optimal: peek\n",
      "[[ 3.105]\n",
      " [ 3.695]\n",
      " [ 2.895]]\n",
      "                             [ 0.1  0.9]\t mls: guessAd\t avs: guessAd\t qmdp: guessAd \t optimal: guessAd\n",
      "[[ 3.105]\n",
      " [ 2.895]\n",
      " [ 3.695]]\n",
      "                             [ 0.9  0.1]\t mls: guessAc\t avs: guessAc\t qmdp: guessAc \t optimal: guessAc\n",
      "[[ 3.105     ]\n",
      " [ 2.80719512]\n",
      " [ 3.78280488]]\n",
      "               [ 0.98780488  0.01219512]\t mls: guessAc\t avs: guessAc\t qmdp: guessAc \t optimal: guessAc\n",
      "[[ 3.105     ]\n",
      " [ 3.78280488]\n",
      " [ 2.80719512]]\n",
      "               [ 0.01219512  0.98780488]\t mls: guessAd\t avs: guessAd\t qmdp: guessAd \t optimal: guessAd\n",
      "[[ 3.105     ]\n",
      " [ 3.79363014]\n",
      " [ 2.79636986]]\n",
      "               [ 0.00136986  0.99863014]\t mls: guessAd\t avs: guessAd\t qmdp: guessAd \t optimal: guessAd\n",
      "[[ 3.105     ]\n",
      " [ 3.79484761]\n",
      " [ 2.79515239]]\n",
      "     [  1.52392563e-04   9.99847607e-01]\t mls: guessAd\t avs: guessAd\t qmdp: guessAd \t optimal: guessAd\n",
      "[[ 3.105     ]\n",
      " [ 2.79636986]\n",
      " [ 3.79363014]]\n",
      "               [ 0.99863014  0.00136986]\t mls: guessAc\t avs: guessAc\t qmdp: guessAc \t optimal: guessAc\n",
      "[[ 3.105     ]\n",
      " [ 2.79515239]\n",
      " [ 3.79484761]]\n",
      "     [  9.99847607e-01   1.52392563e-04]\t mls: guessAc\t avs: guessAc\t qmdp: guessAc \t optimal: guessAc\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for belief in beliefs:\n",
    "    r= np.einsum('nm,rnm->rn', belief.reshape(1,2), a)\n",
    "    optimal = np.argmin(r)\n",
    "    print('%40s\\t mls: %s\\t avs: %s\\t qmdp: %s \\t optimal: %s' % (belief, actions[mls_heuristic(belief)], actions[avs_heuristic(belief)], actions[qmdp_heuristic(belief)], actions[optimal]))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
